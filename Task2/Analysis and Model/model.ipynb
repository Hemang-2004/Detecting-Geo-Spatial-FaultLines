{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_damage_assessment = pd.read_csv(\"../csv_files/csv_building_damage_assessment.csv\",low_memory=False)\n",
    "name_mapping = pd.read_csv(\"../csv_files/ward_vdcmun_district_name_mapping.csv\",low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumUniqueValues(df, col):\n",
    "    return df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNumUniqueValues(name_mapping, 'district_id')\n",
    "getNumUniqueValues(building_damage_assessment, 'district_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create district_id_name_dict\n",
    "district_id_name_dict = name_mapping.set_index('district_id')['district_name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = name_mapping[name_mapping.duplicated(subset='vdcmun_id', keep=False)]\n",
    "name_mapping = name_mapping.drop_duplicates(subset='vdcmun_id')\n",
    "name_mapping = name_mapping.groupby('vdcmun_id').agg({\n",
    "    'vdcmun_name': 'first',\n",
    "    'district_name': 'first'\n",
    "}).reset_index()\n",
    "vdcmun_id_name_dict = name_mapping.set_index('vdcmun_id')[['vdcmun_name', 'district_name']].to_dict('index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df_columns = building_damage_assessment.iloc[:, :54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map vdcmun_id to vdcmun_name and district_name\n",
    "main_df_columns['vdcmun_name'] = main_df_columns['vdcmun_id'].map(lambda x: vdcmun_id_name_dict[x]['vdcmun_name'])\n",
    "main_df_columns['district_name'] = main_df_columns['vdcmun_id'].map(lambda x: vdcmun_id_name_dict[x]['district_name'])\n",
    "\n",
    "# Reorder columns\n",
    "cols = list(main_df_columns.columns)\n",
    "cols.insert(cols.index('vdcmun_id'), cols.pop(cols.index('vdcmun_name')))\n",
    "cols.insert(cols.index('district_id'), cols.pop(cols.index('district_name')))\n",
    "main_df_columns = main_df_columns[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_unique_values(df, col_number):\n",
    "    print(\"Name of the column: \", df.columns[col_number])\n",
    "    return df.iloc[:, col_number].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cramér's V: 0.5618371122498683\n",
      "Column name is: damage_overall_collapse\n",
      "Cramér's V: 0.2851951023763733\n",
      "Column name is: damage_overall_leaning\n",
      "Cramér's V: 0.25243262743853423\n",
      "Column name is: damage_foundation_severe\n",
      "Cramér's V: 0.22690109928414273\n",
      "Column name is: damage_roof_severe\n",
      "Cramér's V: 0.2520240002737159\n",
      "Column name is: damage_corner_separation_severe\n",
      "Cramér's V: 0.23537221388176963\n",
      "Column name is: damage_diagonal_cracking_severe\n",
      "Cramér's V: 0.24912822925831293\n",
      "Column name is: damage_in_plane_failure_severe\n",
      "Cramér's V: 0.23494034724518376\n",
      "Column name is: damage_out_of_plane_failure_severe\n",
      "Cramér's V: 0.21416783899299252\n",
      "Column name is: damage_out_of_plane_failure_walls_ncfr_severe\n",
      "Cramér's V: 0.22644795396018566\n",
      "Column name is: damage_delamination_failure_severe\n",
      "Cramér's V: 0.34345420751380434\n",
      "Column name is: damage_column_failure_severe\n",
      "Cramér's V: 0.45500037465583076\n",
      "Column name is: damage_beam_failure_severe\n",
      "Cramér's V: 0.3362346854327424\n",
      "Column name is: damage_infill_partition_failure_severe\n",
      "Cramér's V: 0.2544384463831442\n",
      "Column name is: damage_infill_partition_failure_moderate\n",
      "Cramér's V: 0.20708664041917418\n",
      "Column name is: damage_parapet_severe\n",
      "Cramér's V: 0.3412349035484076\n",
      "Column name is: damage_cladding_glazing_severe\n",
      "Cramér's V: 0.4049739722835882\n",
      "Column name is: area_assesed\n"
     ]
    }
   ],
   "source": [
    "target_column = 'damage_grade'\n",
    "cramerV_list = []\n",
    "processed_df = main_df_columns.iloc[:, :6]\n",
    "\n",
    "for i in range(6, 55):\n",
    "    entry_column = main_df_columns.columns[i]\n",
    "\n",
    "    # Check for non-NaN and sufficient unique values\n",
    "    if main_df_columns[entry_column].nunique() < 2:\n",
    "        print(f\"Skipping column {entry_column} due to insufficient unique values.\")\n",
    "        continue\n",
    "\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(main_df_columns[entry_column], main_df_columns[target_column])\n",
    "\n",
    "    # Skip if the contingency table is empty\n",
    "    if contingency_table.size == 0:\n",
    "        print(f\"Skipping column {entry_column} due to an empty contingency table.\")\n",
    "        continue\n",
    "\n",
    "    # Perform chi-squared test\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Calculate Cramér's V\n",
    "    n = contingency_table.sum().sum()  # Total number of observations\n",
    "    cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
    "\n",
    "    if cramers_v > 0.2:\n",
    "        cramerV_list.append(cramers_v)\n",
    "        print(\"Cramér's V:\", cramers_v)\n",
    "        print(\"Column name is:\", entry_column)\n",
    "        processed_df = pd.concat([processed_df, main_df_columns[[entry_column]]], axis=1)\n",
    "\n",
    "# Add the target column to the processed DataFrame\n",
    "processed_df = pd.concat([processed_df, main_df_columns[[target_column]]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.columns\n",
    "clustering_df = processed_df.copy()\n",
    "damage_grade_df = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damage = damage_grade_df.copy()\n",
    "\n",
    "def drop_col_from_df(df, col):\n",
    "    return df.drop(col, axis=1)\n",
    "\n",
    "df_damage = drop_col_from_df(df_damage, 'building_id')\n",
    "df_damage = drop_col_from_df(df_damage, 'district_name')\n",
    "df_damage = drop_col_from_df(df_damage, 'district_id')\n",
    "df_damage = drop_col_from_df(df_damage, 'vdcmun_name')\n",
    "df_damage = drop_col_from_df(df_damage, 'vdcmun_id')\n",
    "df_damage = drop_col_from_df(df_damage, 'ward_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damage = df_damage.dropna(subset=['damage_grade']) # drop rows with missing target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do label encodeing on all columns in df_damage\n",
    "label_encoders = {}\n",
    "for col in df_damage.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_damage[col] = le.fit_transform(df_damage[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "X = df_damage.drop('damage_grade', axis=1)\n",
    "y = df_damage['damage_grade']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Initializing KNN model...\n",
      "KNN model initialized.\n",
      "\n",
      "Step 4: Fitting the KNN model...\n",
      "Model fitting completed.\n",
      "\n",
      "Step 5: Making predictions on the test set...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize the KNN model\n",
    "print(\"Step 3: Initializing KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors as needed\n",
    "print(\"KNN model initialized.\\n\")\n",
    "\n",
    "# Step 4: Fit the model to the training data\n",
    "print(\"Step 4: Fitting the KNN model...\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"Model fitting completed.\\n\")\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "print(\"Step 5: Making predictions on the test set...\")\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "print(\"Predictions completed.\\n\")\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "print(\"Step 6: Evaluating the model...\")\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "print(f\"Accuracy on Test Set (KNN): {accuracy_knn}\")\n",
    "print(\"Classification Report (KNN):\\n\", report_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
